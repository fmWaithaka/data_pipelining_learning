# Data Pipeline with Airflow & Docker

A scalable ETL pipeline for copying data from a source database to a target database using Apache Airflow and Docker, with parallel processing capabilities.

## ðŸ“¦ Project Structure

```
.
â”œâ”€â”€ dags/                           # Airflow DAG definitions
â”‚   â””â”€â”€ data_pipeline.py            # Main pipeline DAG
â”œâ”€â”€ src/                            # ETL application code
â”‚   â”œâ”€â”€ app.py                      # Main application entry point
â”‚   â”œâ”€â”€ config.py                   # Database configuration loader
â”‚   â”œâ”€â”€ process.py                  # Data processing utilities
â”‚   â”œâ”€â”€ read.py                     # Source database reading operations
â”‚   â””â”€â”€ write.py                    # Target database writing operations
    â”œâ”€â”€ tables_list                     # List of tables to process
    â”œâ”€â”€ Dockerfile                      # Data pipeline image definition
    â”œâ”€â”€ requirements.txt                # Python dependencies
```

## ðŸš€ Features

- **Parallel Data Processing**: Split table processing across multiple Docker containers
- **Database Agnostic**: Supports MySQL (source) and PostgreSQL (target) 
- **Airflow Integration**: Managed workflow scheduling and monitoring
- **Dockerized**: Containerized execution for reproducibility
- **Error Handling**: Data validation and duplicate key management

## âš™ï¸ Technologies

- Apache Airflow
- Docker
- PostgreSQL
- MySQL
- Python 3.10+

## ðŸ› ï¸ Installation

### Prerequisites
- Docker & Docker Compose
- Apache Airflow (via Docker recommended)
- Python 3.10+

```bash
# Install Python dependencies
pip install -r requirements.txt
```

## ðŸƒâ™€ï¸ Getting Started

### 1. Database Setup
Create source (MySQL) and target (PostgreSQL) databases with matching schemas.

### 2. Build Data Pipeline Image
```bash
docker build -t data-pipeline:latest .
```

### 3. Create Docker Network
```bash
docker network create my_pipeline_network
```

### 4. Configure Airflow
```yaml
# docker-compose.yml (partial)
services:
  airflow-webserver:
    volumes:
      - ./dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - my_pipeline_network
```

### 5. Run Airflow Services
```bash
docker-compose up -d
```

## ðŸ“Š Pipeline Execution

### Trigger DAG
1. Access Airflow UI at `http://localhost:8080`
2. Enable and trigger `data-pipeline-parallel` DAG

### Expected Flow
```mermaid
graph TD
    A[Start] --> B[Copy Customers & Categories]
    A --> C[Copy Products & Departments]
    A --> D[Copy Orders]
    A --> E[Copy Order Items]
    B --> F[End]
    C --> F
    D --> F
    E --> F
```

## ðŸ”§ Configuration

### Environment Variables
```python
# In DAG definition
env_vars = {
    'SOURCE_DB_USER': 'retail_user',
    'SOURCE_DB_PASS': 'itversity',
    'TARGET_DB_USER': 'retail_user',
    'TARGET_DB_PASS': 'itversity'
}
```

### Table Configuration
Update `tables_list` with your source database tables:
```
customers
orders
order_items
products
categories
departments
```

## ðŸ§  Customization

### Parallel Processing
Adjust task groups in `data_pipeline.py`:
```python
table_groups = [
    {'task_id': 'copy_customers_categories', 'tables': ['customers', 'categories']},
    {'task_id': 'copy_products_departments', 'tables': ['products', 'departments']},
    {'task_id': 'copy_orders', 'tables': ['orders']},
    {'task_id': 'copy_order_items', 'tables': ['order_items']}
]
```

### Scheduling
Modify DAG schedule interval:
```python
dag = DAG(
    ...
    schedule_interval='0 0 * * *',  # Daily at midnight
    ...
)
```

## ðŸš¨ Troubleshooting

Common Issues:
1. **Docker Permission Denied**
   ```bash
   sudo usermod -aG docker $USER
   newgrp docker
   ```

2. **Database Connection Issues**
   - Verify network configuration
   - Check firewall rules
   - Validate credentials

3. **Duplicate Key Errors**
   ```postgres
   TRUNCATE TABLE 
      order_items,
      orders,
      products,
      categories,
      departments,
      customers
    RESTART IDENTITY CASCADE;
   ```

4. **Airflow UI Not Updating**
   ```bash
   airflow db reset
   airflow webserver --restart
   ```

## ðŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

## ðŸ“§ Contact

[Waithaka Francis] - [waithakaf483@gmail.com]
